{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hasyimabdillah/dicoding-tfdc-exam-simulation-b?scriptVersionId=99230558\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","execution_count":1,"id":"cab0e789","metadata":{"execution":{"iopub.execute_input":"2022-06-24T15:12:36.480165Z","iopub.status.busy":"2022-06-24T15:12:36.47968Z","iopub.status.idle":"2022-06-24T15:12:46.150737Z","shell.execute_reply":"2022-06-24T15:12:46.148738Z"},"papermill":{"duration":9.679181,"end_time":"2022-06-24T15:12:46.153856","exception":false,"start_time":"2022-06-24T15:12:36.474675","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-24 15:12:41.912684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:42.012153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:42.012866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:42.014843: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-06-24 15:12:42.019076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:42.019810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:42.020538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:44.100206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:44.100941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:44.101675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-24 15:12:44.102287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2022-06-24 15:12:44.481527: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 1s 1s/step - loss: 132.2697\n","Epoch 2/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00\n","[[-1.]\n"," [23.]]\n"]}],"source":["# =============================================================================\n","# PROBLEM B1\n","#\n","# Given two arrays, train a neural network model to match the X to the Y.\n","# Predict the model with new values of X [-2.0, 10.0]\n","# We provide the model prediction, do not change the code.\n","#\n","# The test infrastructure expects a trained model that accepts\n","# an input shape of [1]\n","# Do not use lambda layers in your model.\n","#\n","# Please be aware that this is a linear model.\n","# We will test your model with values in a range as defined in the array to make sure your model is linear.\n","#\n","# Desired loss (MSE) < 1e-3\n","# =============================================================================\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('loss') < 1e-3):\n","            self.model.stop_training = True\n","\n","def solution_B1():\n","    # DO NOT CHANGE THIS CODE\n","    X = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], dtype=float)\n","    Y = np.array([5.0, 7.0, 9.0, 11.0, 13.0, 15.0, 17.0], dtype=float)\n","\n","    layer_norm = keras.layers.Normalization(input_shape = [1], axis = None)\n","    layer_norm.adapt(X)\n","    \n","    model = tf.keras.models.Sequential([\n","        layer_norm,\n","        keras.layers.Dense(1)\n","    ])\n","    \n","    model.compile(loss = 'mean_squared_error',\n","                  optimizer = keras.optimizers.SGD(learning_rate = 0.5)\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(X,\n","              Y,\n","              epochs = 100,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    print(model.predict([-2.0, 10.0]))\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_B1()\n","    model.save(\"model_B1.h5\")\n"]},{"cell_type":"code","execution_count":2,"id":"d2aa67f0","metadata":{"execution":{"iopub.execute_input":"2022-06-24T15:12:46.162448Z","iopub.status.busy":"2022-06-24T15:12:46.162176Z","iopub.status.idle":"2022-06-24T15:12:58.21257Z","shell.execute_reply":"2022-06-24T15:12:58.21163Z"},"papermill":{"duration":12.056868,"end_time":"2022-06-24T15:12:58.214713","exception":false,"start_time":"2022-06-24T15:12:46.157845","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 1s 0us/step\n","26435584/26421880 [==============================] - 1s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","Epoch 1/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.5002 - accuracy: 0.8249 - val_loss: 0.4237 - val_accuracy: 0.8502\n","Epoch 2/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3790 - accuracy: 0.8621 - val_loss: 0.3964 - val_accuracy: 0.8518\n"]}],"source":["# =============================================================================\n","# PROBLEM B2\n","#\n","# Build a classifier for the Fashion MNIST dataset.\n","# The test will expect it to classify 10 classes.\n","# The input shape should be 28x28 monochrome. Do not resize the data.\n","# Your input layer should accept (28, 28) as the input shape.\n","#\n","# Don't use lambda layers in your model.\n","#\n","# Desired accuracy AND validation_accuracy > 83%\n","# =============================================================================\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.83 and logs.get('val_accuracy') > 0.83):\n","            self.model.stop_training = True\n","\n","def solution_B2():\n","    fashion_mnist = tf.keras.datasets.fashion_mnist\n","\n","    # NORMALIZE YOUR IMAGE HERE\n","    (feature_train, label_train), (feature_test, label_test) = fashion_mnist.load_data()\n","    \n","    feature_train = feature_train / 255.\n","    \n","    feature_test =feature_test / 255.\n","    \n","    # DEFINE YOUR MODEL HERE\n","    # End with 10 Neuron Dense, activated by softmax\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape = (28, 28)),\n","        tf.keras.layers.Dense(128, activation = 'relu'),\n","        tf.keras.layers.Dense(10, activation = 'softmax')\n","    ])\n","\n","    # COMPILE MODEL HERE\n","    model.compile(loss = 'sparse_categorical_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    # TRAIN YOUR MODEL HERE\n","    model.fit(feature_train,\n","              label_train,\n","              epochs = 10,\n","              validation_data = (feature_test, label_test),\n","              callbacks = [CALLBACK]\n","             )\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_B2()\n","    model.save(\"model_B2.h5\")\n"]},{"cell_type":"code","execution_count":3,"id":"0e4724a1","metadata":{"execution":{"iopub.execute_input":"2022-06-24T15:12:58.240245Z","iopub.status.busy":"2022-06-24T15:12:58.239944Z","iopub.status.idle":"2022-06-24T15:20:40.665921Z","shell.execute_reply":"2022-06-24T15:20:40.664925Z"},"papermill":{"duration":462.441444,"end_time":"2022-06-24T15:20:40.668414","exception":false,"start_time":"2022-06-24T15:12:58.22697","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2268 images belonging to 3 classes.\n","Found 252 images belonging to 3 classes.\n","Epoch 1/100\n","71/71 [==============================] - 17s 236ms/step - loss: 22.2173 - accuracy: 0.3726 - val_loss: 9.5091 - val_accuracy: 0.3333\n","Epoch 2/100\n","71/71 [==============================] - 17s 235ms/step - loss: 4.6455 - accuracy: 0.4224 - val_loss: 7.5887 - val_accuracy: 0.3333\n","Epoch 3/100\n","71/71 [==============================] - 16s 225ms/step - loss: 2.9061 - accuracy: 0.4881 - val_loss: 3.6591 - val_accuracy: 0.4841\n","Epoch 4/100\n","71/71 [==============================] - 16s 229ms/step - loss: 1.3915 - accuracy: 0.6424 - val_loss: 0.6368 - val_accuracy: 0.6905\n","Epoch 5/100\n","71/71 [==============================] - 16s 227ms/step - loss: 1.1911 - accuracy: 0.6777 - val_loss: 0.5271 - val_accuracy: 0.8175\n","Epoch 6/100\n","71/71 [==============================] - 17s 234ms/step - loss: 1.9814 - accuracy: 0.6155 - val_loss: 2.5415 - val_accuracy: 0.3373\n","Epoch 7/100\n","71/71 [==============================] - 17s 233ms/step - loss: 1.0531 - accuracy: 0.6861 - val_loss: 2.3950 - val_accuracy: 0.5675\n","Epoch 8/100\n","71/71 [==============================] - 16s 232ms/step - loss: 1.2071 - accuracy: 0.6795 - val_loss: 0.9750 - val_accuracy: 0.4683\n","Epoch 9/100\n","71/71 [==============================] - 16s 230ms/step - loss: 0.6084 - accuracy: 0.7897 - val_loss: 0.6899 - val_accuracy: 0.6429\n","Epoch 10/100\n","71/71 [==============================] - 16s 231ms/step - loss: 0.7027 - accuracy: 0.7469 - val_loss: 0.6750 - val_accuracy: 0.6627\n","Epoch 11/100\n","71/71 [==============================] - 16s 230ms/step - loss: 0.6466 - accuracy: 0.7769 - val_loss: 2.7294 - val_accuracy: 0.3333\n","Epoch 12/100\n","71/71 [==============================] - 17s 233ms/step - loss: 1.2684 - accuracy: 0.6720 - val_loss: 2.2210 - val_accuracy: 0.6270\n","Epoch 13/100\n","71/71 [==============================] - 16s 228ms/step - loss: 0.8781 - accuracy: 0.7584 - val_loss: 1.1719 - val_accuracy: 0.4127\n","Epoch 14/100\n","71/71 [==============================] - 16s 231ms/step - loss: 0.3743 - accuracy: 0.8598 - val_loss: 0.9457 - val_accuracy: 0.4643\n","Epoch 15/100\n","71/71 [==============================] - 16s 228ms/step - loss: 0.5337 - accuracy: 0.7967 - val_loss: 1.0390 - val_accuracy: 0.4286\n","Epoch 16/100\n","71/71 [==============================] - 17s 233ms/step - loss: 0.4866 - accuracy: 0.8170 - val_loss: 1.4900 - val_accuracy: 0.6151\n","Epoch 17/100\n","71/71 [==============================] - 16s 230ms/step - loss: 0.5820 - accuracy: 0.7800 - val_loss: 2.0857 - val_accuracy: 0.3333\n","Epoch 18/100\n","71/71 [==============================] - 16s 232ms/step - loss: 0.6196 - accuracy: 0.7628 - val_loss: 0.4685 - val_accuracy: 0.8016\n","Epoch 19/100\n","71/71 [==============================] - 16s 227ms/step - loss: 0.4271 - accuracy: 0.8430 - val_loss: 0.8517 - val_accuracy: 0.5198\n","Epoch 20/100\n","71/71 [==============================] - 17s 236ms/step - loss: 0.3068 - accuracy: 0.8827 - val_loss: 0.5244 - val_accuracy: 0.7937\n","Epoch 21/100\n","71/71 [==============================] - 16s 228ms/step - loss: 0.4734 - accuracy: 0.8263 - val_loss: 0.4694 - val_accuracy: 0.8254\n","Epoch 22/100\n","71/71 [==============================] - 17s 237ms/step - loss: 0.7988 - accuracy: 0.7231 - val_loss: 1.5306 - val_accuracy: 0.6071\n","Epoch 23/100\n","71/71 [==============================] - 16s 227ms/step - loss: 0.4437 - accuracy: 0.8245 - val_loss: 0.5986 - val_accuracy: 0.6865\n","Epoch 24/100\n","71/71 [==============================] - 17s 233ms/step - loss: 0.2876 - accuracy: 0.8995 - val_loss: 0.7434 - val_accuracy: 0.6310\n","Epoch 25/100\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2784 - accuracy: 0.9004 - val_loss: 0.6419 - val_accuracy: 0.6865\n","Epoch 26/100\n","71/71 [==============================] - 17s 236ms/step - loss: 0.2283 - accuracy: 0.9171 - val_loss: 0.3313 - val_accuracy: 0.9167\n"]}],"source":["# ========================================================================================\n","# PROBLEM B3\n","#\n","# Build a CNN based classifier for Rock-Paper-Scissors dataset.\n","# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n","# This is unlabeled data, use ImageDataGenerator to automatically label it.\n","# Don't use lambda layers in your model.\n","#\n","# The dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n","#\n","# Desired accuracy AND validation_accuracy > 83%\n","# ========================================================================================\n","\n","import urllib.request\n","import zipfile\n","import tensorflow as tf\n","import os\n","from keras_preprocessing.image import ImageDataGenerator\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.83 and logs.get('val_accuracy') > 0.83):\n","            self.model.stop_training = True\n","\n","def solution_B3():\n","    data_url = 'https://github.com/dicodingacademy/assets/releases/download/release-rps/rps.zip'\n","    urllib.request.urlretrieve(data_url, 'rps.zip')\n","    local_file = 'rps.zip'\n","    zip_ref = zipfile.ZipFile(local_file, 'r')\n","    zip_ref.extractall('data/')\n","    zip_ref.close()\n","\n","    TRAINING_DIR = \"data/rps/\"\n","    training_datagen = ImageDataGenerator(rescale = 1./255,\n","                                          rotation_range = 0.2,\n","                                          horizontal_flip = True,\n","                                          vertical_flip = True,\n","                                          fill_mode = 'nearest',\n","                                          validation_split = 0.1\n","                                         )\n","    \n","    val_datagen = ImageDataGenerator(rescale = 1./255,\n","                                     validation_split = 0.1\n","                                    )\n","\n","    # YOUR IMAGE SIZE SHOULD BE 150x150\n","    # Make sure you used \"categorical\"\n","    train_generator = training_datagen.flow_from_directory(directory = TRAINING_DIR,\n","                                                           target_size = (150, 150),\n","                                                           color_mode = 'rgb',\n","                                                           class_mode = 'categorical',\n","                                                           shuffle = True,\n","                                                           batch_size = 32,\n","                                                           seed = 123,\n","                                                           subset = 'training'\n","                                                          )\n","    \n","    val_generator = val_datagen.flow_from_directory(directory = TRAINING_DIR,\n","                                                    target_size = (150, 150),\n","                                                    color_mode = 'rgb',\n","                                                    class_mode = 'categorical',\n","                                                    shuffle = True,\n","                                                    batch_size = 8,\n","                                                    seed = 123,\n","                                                    subset = 'validation'\n","                                                   )\n","\n","    model=tf.keras.models.Sequential([\n","        # YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n","        tf.keras.layers.Flatten(input_shape = (150, 150, 3)),\n","        tf.keras.layers.Dense(512, activation = 'relu'),\n","        tf.keras.layers.Dense(128, activation = 'relu'),\n","        tf.keras.layers.Dense(3, activation = 'softmax')\n","    ])\n","\n","    CALLBACK = myCallback()\n","    \n","    model.compile(loss = 'categorical_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    model.fit(train_generator,\n","              epochs = 100,\n","              validation_data = val_generator,\n","              callbacks = [CALLBACK]\n","             )\n","    \n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model=solution_B3()\n","    model.save(\"model_B3.h5\")\n"]},{"cell_type":"code","execution_count":4,"id":"8f38f92a","metadata":{"execution":{"iopub.execute_input":"2022-06-24T15:20:40.915131Z","iopub.status.busy":"2022-06-24T15:20:40.914626Z","iopub.status.idle":"2022-06-24T15:20:46.370672Z","shell.execute_reply":"2022-06-24T15:20:46.369766Z"},"papermill":{"duration":5.582206,"end_time":"2022-06-24T15:20:46.372761","exception":false,"start_time":"2022-06-24T15:20:40.790555","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["        category                                               text\n","0           tech  tv future in the hands of viewers with home th...\n","1       business  worldcom boss  left books alone  former worldc...\n","2          sport  tigers wary of farrell  gamble  leicester say ...\n","3          sport  yeading face newcastle in fa cup premiership s...\n","4  entertainment  ocean s twelve raids box office ocean s twelve...\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 120, 16)           16000     \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 16)                0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 24)                408       \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 6)                 150       \n","=================================================================\n","Total params: 16,558\n","Trainable params: 16,558\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","56/56 [==============================] - 1s 6ms/step - loss: 1.7674 - accuracy: 0.2438 - val_loss: 1.7344 - val_accuracy: 0.2382\n","Epoch 2/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.6944 - accuracy: 0.2393 - val_loss: 1.6469 - val_accuracy: 0.2966\n","Epoch 3/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.6019 - accuracy: 0.3888 - val_loss: 1.5526 - val_accuracy: 0.4360\n","Epoch 4/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.5008 - accuracy: 0.4635 - val_loss: 1.4488 - val_accuracy: 0.4539\n","Epoch 5/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.3745 - accuracy: 0.5635 - val_loss: 1.3150 - val_accuracy: 0.6000\n","Epoch 6/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.2160 - accuracy: 0.6573 - val_loss: 1.1554 - val_accuracy: 0.7348\n","Epoch 7/100\n","56/56 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.7809 - val_loss: 0.9903 - val_accuracy: 0.8292\n","Epoch 8/100\n","56/56 [==============================] - 0s 3ms/step - loss: 0.8638 - accuracy: 0.8640 - val_loss: 0.8419 - val_accuracy: 0.8607\n","Epoch 9/100\n","56/56 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.8944 - val_loss: 0.7082 - val_accuracy: 0.8944\n","Epoch 10/100\n","56/56 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.9219 - val_loss: 0.6096 - val_accuracy: 0.8899\n","Epoch 11/100\n","56/56 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.9348 - val_loss: 0.5276 - val_accuracy: 0.9034\n","Epoch 12/100\n","56/56 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.9433 - val_loss: 0.4712 - val_accuracy: 0.9124\n"]}],"source":["# ===================================================================================================\n","# PROBLEM B4\n","#\n","# Build and train a classifier for the BBC-text dataset.\n","# This is a multiclass classification problem.\n","# Do not use lambda layers in your model.\n","#\n","# The dataset used in this problem is originally published in: http://mlg.ucd.ie/datasets/bbc.html.\n","#\n","# Desired accuracy and validation_accuracy > 91%\n","# ===================================================================================================\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.91 and logs.get('val_accuracy') > 0.91):\n","            self.model.stop_training = True\n","\n","def solution_B4():\n","    bbc = pd.read_csv(\n","        'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/bbc-text.csv')\n","\n","    # DO NOT CHANGE THIS CODE\n","    # Make sure you used all of these parameters or you can not pass this test\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type = 'post'\n","    padding_type = 'post'\n","    oov_tok = \"<OOV>\"\n","    training_portion = .8\n","\n","    # YOUR CODE HERE\n","    # Using \"shuffle=False\"\n","    print(bbc.head(5))\n","    \n","    features = bbc.text\n","    labels = bbc.category\n","    \n","    features_train, features_test, labels_train, labels_test = train_test_split(features,\n","                                                                                labels,\n","                                                                                train_size = training_portion,\n","                                                                                shuffle = False\n","                                                                               )\n","\n","    # Fit your tokenizer with training data\n","    tokenizer =  Tokenizer(num_words = vocab_size,\n","                           oov_token = oov_tok\n","                          )\n","    tokenizer.fit_on_texts(features_train)\n","    word_index = tokenizer.word_index\n","    \n","    train_sequences = tokenizer.texts_to_sequences(features_train)\n","    features_train = pad_sequences(train_sequences, \n","                                   maxlen = max_length, \n","                                   truncating = trunc_type, \n","                                   padding = padding_type\n","                                  )\n","    \n","    test_sequences = tokenizer.texts_to_sequences(features_test)\n","    features_test = pad_sequences(test_sequences, \n","                                  maxlen = max_length, \n","                                  truncating = trunc_type,\n","                                  padding = padding_type\n","                                 )\n","    \n","    label_tokenizer = Tokenizer()\n","    label_tokenizer.fit_on_texts(labels)\n","    \n","    labels_train = np.array(label_tokenizer.texts_to_sequences(labels_train))\n","    labels_test = np.array(label_tokenizer.texts_to_sequences(labels_test))\n","    \n","    model = tf.keras.Sequential([\n","        # YOUR CODE HERE.\n","        # YOUR CODE HERE. DO not change the last layer or test may fail\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n","        tf.keras.layers.GlobalAveragePooling1D(),\n","        tf.keras.layers.Dense(24, activation = 'relu'),\n","        tf.keras.layers.Dense(6, activation='softmax')\n","    ])\n","    \n","    model.summary()\n","\n","    # Make sure you are using \"sparse_categorical_crossentropy\" as a loss fuction\n","    model.compile(loss = 'sparse_categorical_crossentropy',\n","                  optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","\n","    model.fit(features_train,\n","              labels_train,\n","              epochs = 100,\n","              validation_data = (features_test, labels_test),\n","              callbacks = [CALLBACK]\n","             )\n","    \n","    return model\n","\n","    # The code below is to save your model as a .h5 file.\n","    # It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_B4()\n","    model.save(\"model_B4.h5\")\n"]},{"cell_type":"code","execution_count":5,"id":"be692a84","metadata":{"execution":{"iopub.execute_input":"2022-06-24T15:20:46.625148Z","iopub.status.busy":"2022-06-24T15:20:46.624774Z","iopub.status.idle":"2022-06-24T15:20:59.943069Z","shell.execute_reply":"2022-06-24T15:20:59.94215Z"},"papermill":{"duration":13.446179,"end_time":"2022-06-24T15:20:59.945156","exception":false,"start_time":"2022-06-24T15:20:46.498977","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<PrefetchDataset shapes: ((None, None, 1), (None, None, 1)), types: (tf.float64, tf.float64)>\n","(2500,)\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2022-06-24 15:20:48.314173: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["10/10 [==============================] - 6s 17ms/step - loss: 0.0957 - mae: 0.2654\n","Epoch 2/10\n","10/10 [==============================] - 0s 25ms/step - loss: 0.0442 - mae: 0.1573\n","Epoch 3/10\n","10/10 [==============================] - 0s 24ms/step - loss: 0.0268 - mae: 0.1154\n","Epoch 4/10\n","10/10 [==============================] - 0s 23ms/step - loss: 0.0200 - mae: 0.1003\n","Epoch 5/10\n","10/10 [==============================] - 0s 24ms/step - loss: 0.0171 - mae: 0.0949\n"]}],"source":["# ============================================================================================\n","# PROBLEM B5\n","#\n","# Build and train a neural network model using the Daily Max Temperature.csv dataset.\n","# Use MAE as the metrics of your neural network model.\n","# We provided code for normalizing the data. Please do not change the code.\n","# Do not use lambda layers in your model.\n","#\n","# The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n","#\n","# Desired MAE < 0.2 on the normalized dataset.\n","# ============================================================================================\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","import urllib\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('mae') < 0.2 and epoch > 3):\n","            self.model.stop_training = True\n","\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_B5():\n","    data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-max-temperatures.csv'\n","    urllib.request.urlretrieve(data_url, 'daily-max-temperatures.csv')\n","\n","    time_step = []\n","    temps = []\n","\n","    with open('daily-max-temperatures.csv') as csvfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","        next(reader)\n","        step = 0\n","        for row in reader:\n","            temps.append(row[1])\n","            time_step.append(step)\n","            step = step + 1\n","\n","    series = np.array(temps).astype(np.float64)\n","\n","    # Normalization Function. DO NOT CHANGE THIS CODE\n","    min=np.min(series)\n","    max=np.max(series)\n","    series -= min\n","    series /= max\n","    time=np.array(time_step)\n","\n","    # DO NOT CHANGE THIS CODE\n","    split_time=2500\n","\n","    time_train = time[:split_time]\n","    x_train = series[:split_time]\n","    time_valid = time[split_time:]\n","    x_valid = series[split_time:]\n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size=64\n","    batch_size=256\n","    shuffle_buffer_size=1000\n","\n","    train_set=windowed_dataset(\n","        x_train, window_size, batch_size, shuffle_buffer_size)\n","    print(train_set)\n","    print(x_train.shape)\n","\n","    model=tf.keras.models.Sequential([\n","        # YOUR CODE HERE.\n","        tf.keras.layers.Conv1D(32, kernel_size = 1, input_shape = [None, 1]),\n","        tf.keras.layers.Dense(16, activation = 'relu'),\n","        tf.keras.layers.Dense(1),\n","    ])\n","    \n","    model.compile(loss = 'mse',\n","                  optimizer = 'sgd',\n","                  metrics = ['mae']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(train_set,\n","              epochs = 10,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    # YOUR CODE HERE\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model=solution_B5()\n","    model.save(\"model_B5.h5\")\n"]},{"cell_type":"code","execution_count":null,"id":"96e19740","metadata":{"papermill":{"duration":0.129398,"end_time":"2022-06-24T15:21:00.204386","exception":false,"start_time":"2022-06-24T15:21:00.074988","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":514.655329,"end_time":"2022-06-24T15:21:03.231278","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-06-24T15:12:28.575949","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}