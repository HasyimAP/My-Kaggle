{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hasyimabdillah/dicoding-tfdc-exam-simulation-c?scriptVersionId=99366222\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","execution_count":1,"id":"1b7d70ff","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:21:50.305115Z","iopub.status.busy":"2022-06-26T14:21:50.304569Z","iopub.status.idle":"2022-06-26T14:21:59.979476Z","shell.execute_reply":"2022-06-26T14:21:59.978025Z"},"papermill":{"duration":9.682603,"end_time":"2022-06-26T14:21:59.981716","exception":false,"start_time":"2022-06-26T14:21:50.299113","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-26 14:21:55.592780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:55.686542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:55.687472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:55.689505: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-06-26 14:21:55.694002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:55.694748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:55.695438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:57.738017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:57.738841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:57.739541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:21:57.740153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2022-06-26 14:21:58.157037: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 1s 1s/step - loss: 21.4346\n","Epoch 2/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.5002\n","Epoch 3/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.3082\n","Epoch 4/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.2341\n","Epoch 5/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1841\n","Epoch 6/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1471\n","Epoch 7/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1182\n","Epoch 8/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0953\n","Epoch 9/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0770\n","Epoch 10/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0624\n","Epoch 11/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0506\n","Epoch 12/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0411\n","Epoch 13/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0334\n","Epoch 14/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0272\n","Epoch 15/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0222\n","Epoch 16/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0181\n","Epoch 17/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0147\n","Epoch 18/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0120\n","Epoch 19/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0098\n","Epoch 20/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0080\n","Epoch 21/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0065\n","Epoch 22/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0053\n","Epoch 23/100\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0044\n","Epoch 24/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0036\n","Epoch 25/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0029\n","Epoch 26/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n","Epoch 27/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n","Epoch 28/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n","Epoch 29/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n","Epoch 30/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n","Epoch 31/100\n","1/1 [==============================] - 0s 3ms/step - loss: 8.6825e-04\n","Epoch 32/100\n","1/1 [==============================] - 0s 3ms/step - loss: 7.0982e-04\n","Epoch 33/100\n","1/1 [==============================] - 0s 4ms/step - loss: 5.8032e-04\n","Epoch 34/100\n","1/1 [==============================] - 0s 4ms/step - loss: 4.7446e-04\n","Epoch 35/100\n","1/1 [==============================] - 0s 3ms/step - loss: 3.8793e-04\n","Epoch 36/100\n","1/1 [==============================] - 0s 5ms/step - loss: 3.1718e-04\n","Epoch 37/100\n","1/1 [==============================] - 0s 4ms/step - loss: 2.5934e-04\n","Epoch 38/100\n","1/1 [==============================] - 0s 4ms/step - loss: 2.1206e-04\n","Epoch 39/100\n","1/1 [==============================] - 0s 6ms/step - loss: 1.7340e-04\n","Epoch 40/100\n","1/1 [==============================] - 0s 4ms/step - loss: 1.4178e-04\n","Epoch 41/100\n","1/1 [==============================] - 0s 5ms/step - loss: 1.1594e-04\n","Epoch 42/100\n","1/1 [==============================] - 0s 4ms/step - loss: 9.4803e-05\n","[[-0.01925278]\n"," [ 6.022014  ]]\n"]}],"source":["# =============================================================================\n","# PROBLEM C1\n","#\n","# Given two arrays, train a neural network model to match the X to the Y.\n","# Predict the model with new values of X [-2.0, 10.0]\n","# We provide the model prediction, do not change the code.\n","#\n","# The test infrastructure expects a trained model that accepts\n","# an input shape of [1]\n","# Do not use lambda layers in your model.\n","#\n","# Please be aware that this is a linear model.\n","# We will test your model with values in a range as defined in the array to make sure your model is linear.\n","#\n","# Desired loss (MSE) < 1e-4\n","# =============================================================================\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('loss') < 1e-4):\n","            self.model.stop_training = True\n","\n","def solution_C1():\n","    # DO NOT CHANGE THIS CODE\n","    X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n","    Y = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)\n","\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Dense(1, input_shape = [1]),\n","        tf.keras.layers.Dense(1)\n","    ])\n","    \n","    model.compile(loss = 'mse',\n","                  optimizer = tf.keras.optimizers.SGD(learning_rate = 0.05)\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(X,\n","              Y,\n","              epochs = 100,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    print(model.predict([-2.0, 10.0]))\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C1()\n","    model.save(\"model_C1.h5\")\n"]},{"cell_type":"code","execution_count":2,"id":"a0d241d2","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:21:59.999822Z","iopub.status.busy":"2022-06-26T14:21:59.999038Z","iopub.status.idle":"2022-06-26T14:22:05.849936Z","shell.execute_reply":"2022-06-26T14:22:05.848983Z"},"papermill":{"duration":5.862015,"end_time":"2022-06-26T14:22:05.852306","exception":false,"start_time":"2022-06-26T14:21:59.990291","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/100\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2014 - accuracy: 0.9406 - val_loss: 0.1044 - val_accuracy: 0.9660\n"]}],"source":["# =============================================================================\n","# PROBLEM C2\n","#\n","# Create a classifier for the MNIST Handwritten digit dataset.\n","# The test will expect it to classify 10 classes.\n","#\n","# Don't use lambda layers in your model.\n","#\n","# Desired accuracy AND validation_accuracy > 91%\n","# =============================================================================\n","\n","import tensorflow as tf\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.91 and logs.get('val_accuracy') > 0.91):\n","            self.model.stop_training = True\n","\n","def solution_C2():\n","    mnist = tf.keras.datasets.mnist\n","\n","    # NORMALIZE YOUR IMAGE HERE\n","    (images_train, labels_train), (images_test, labels_test) = mnist.load_data()\n","    \n","    images_train = images_train / 255.\n","    images_test = images_test / 255.\n","\n","    # DEFINE YOUR MODEL HERE\n","    # End with 10 Neuron Dense, activated by softmax\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape = (28, 28)),\n","        tf.keras.layers.Dense(512, activation = 'relu'),\n","        tf.keras.layers.Dense(10, activation = 'softmax')\n","    ])\n","\n","    # COMPILE MODEL HERE\n","    model.compile(loss = 'sparse_categorical_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","\n","    # TRAIN YOUR MODEL HERE\n","    CALLBACK = myCallback()\n","    \n","    model.fit(images_train,\n","              labels_train,\n","              epochs = 100,\n","              validation_data = (images_test, labels_test),\n","              callbacks = [CALLBACK]\n","             )\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C2()\n","    model.save(\"model_C2.h5\")\n"]},{"cell_type":"code","execution_count":3,"id":"febebc68","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:22:05.87928Z","iopub.status.busy":"2022-06-26T14:22:05.87847Z","iopub.status.idle":"2022-06-26T14:26:34.55692Z","shell.execute_reply":"2022-06-26T14:26:34.555934Z"},"papermill":{"duration":268.694063,"end_time":"2022-06-26T14:26:34.559294","exception":false,"start_time":"2022-06-26T14:22:05.865231","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n","Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2022-06-26 14:22:12.963079: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["125/125 [==============================] - 24s 137ms/step - loss: 0.7062 - accuracy: 0.5535 - val_loss: 0.7526 - val_accuracy: 0.4990\n","Epoch 2/100\n","125/125 [==============================] - 17s 133ms/step - loss: 0.6800 - accuracy: 0.5820 - val_loss: 0.7748 - val_accuracy: 0.5020\n","Epoch 3/100\n","125/125 [==============================] - 17s 136ms/step - loss: 0.6727 - accuracy: 0.5965 - val_loss: 0.8244 - val_accuracy: 0.5040\n","Epoch 4/100\n","125/125 [==============================] - 17s 133ms/step - loss: 0.6484 - accuracy: 0.6300 - val_loss: 0.6552 - val_accuracy: 0.5968\n","Epoch 5/100\n","125/125 [==============================] - 17s 135ms/step - loss: 0.6332 - accuracy: 0.6605 - val_loss: 0.6727 - val_accuracy: 0.6260\n","Epoch 6/100\n","125/125 [==============================] - 17s 133ms/step - loss: 0.6106 - accuracy: 0.6720 - val_loss: 0.7179 - val_accuracy: 0.5736\n","Epoch 7/100\n","125/125 [==============================] - 17s 133ms/step - loss: 0.5995 - accuracy: 0.6860 - val_loss: 0.5908 - val_accuracy: 0.6835\n","Epoch 8/100\n","125/125 [==============================] - 17s 136ms/step - loss: 0.5794 - accuracy: 0.7080 - val_loss: 0.7012 - val_accuracy: 0.6260\n","Epoch 9/100\n","125/125 [==============================] - 17s 135ms/step - loss: 0.5702 - accuracy: 0.7165 - val_loss: 0.6401 - val_accuracy: 0.6230\n","Epoch 10/100\n","125/125 [==============================] - 17s 135ms/step - loss: 0.5599 - accuracy: 0.7220 - val_loss: 0.6059 - val_accuracy: 0.7056\n","Epoch 11/100\n","125/125 [==============================] - 17s 134ms/step - loss: 0.5594 - accuracy: 0.7185 - val_loss: 0.6194 - val_accuracy: 0.6472\n","Epoch 12/100\n","125/125 [==============================] - 17s 137ms/step - loss: 0.5513 - accuracy: 0.7250 - val_loss: 0.7996 - val_accuracy: 0.5968\n","Epoch 13/100\n","125/125 [==============================] - 17s 133ms/step - loss: 0.5337 - accuracy: 0.7595 - val_loss: 0.5535 - val_accuracy: 0.7056\n","Epoch 14/100\n","125/125 [==============================] - 17s 137ms/step - loss: 0.5138 - accuracy: 0.7550 - val_loss: 1.0189 - val_accuracy: 0.6431\n","Epoch 15/100\n","125/125 [==============================] - 16s 132ms/step - loss: 0.5115 - accuracy: 0.7590 - val_loss: 0.5846 - val_accuracy: 0.7288\n"]}],"source":["# =======================================================================================================\n","# PROBLEM C3\n","#\n","# Build a CNN based classifier for Cats vs Dogs dataset.\n","# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n","# This is unlabeled data, use ImageDataGenerator to automatically label it.\n","# Don't use lambda layers in your model.\n","#\n","# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n","#\n","# Desired accuracy and validation_accuracy > 72%\n","# ========================================================================================================\n","\n","import tensorflow as tf\n","import urllib.request\n","import zipfile\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.72 and logs.get('val_accuracy') > 0.72):\n","            self.model.stop_training = True\n","\n","def solution_C3():\n","    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n","    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n","    local_file = 'cats_and_dogs.zip'\n","    zip_ref = zipfile.ZipFile(local_file, 'r')\n","    zip_ref.extractall('data/')\n","    zip_ref.close()\n","\n","    BASE_DIR = 'data/cats_and_dogs_filtered'\n","    train_dir = os.path.join(BASE_DIR, 'train')\n","    validation_dir = os.path.join(BASE_DIR, 'validation')\n","\n","    train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                       rotation_range = 0.1,\n","                                       width_shift_range = 0.1,\n","                                       height_shift_range = 0.1,\n","                                       shear_range = 0.1,\n","                                       zoom_range = 0.2,\n","                                       horizontal_flip = True\n","                                      )\n","    \n","    val_datagen = ImageDataGenerator(rescale = 1./255.)\n","\n","    # YOUR IMAGE SIZE SHOULD BE 150x150\n","    # Make sure you used \"binary\"\n","    train_generator = train_datagen.flow_from_directory(directory = train_dir,\n","                                                        target_size = (150, 150),\n","                                                        color_mode = 'rgb',\n","                                                        class_mode = 'binary',\n","                                                        shuffle = True,\n","                                                        batch_size = 16\n","                                                       )\n","    \n","    val_generator = val_datagen.flow_from_directory(directory = validation_dir,\n","                                                    target_size = (150, 150),\n","                                                    color_mode = 'rgb',\n","                                                    class_mode = 'binary',\n","                                                    shuffle = True,\n","                                                    batch_size = 16\n","                                                   )\n","    \n","    model = tf.keras.models.Sequential([\n","        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n","        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), input_shape = (150, 150, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(16, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(64, activation = 'relu'),\n","        tf.keras.layers.Dense(32, activation = 'relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(1, activation = 'sigmoid')\n","    ])\n","    \n","    model.compile(loss = 'binary_crossentropy',\n","                  optimizer = RMSprop(learning_rate = 1e-3),\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(train_generator,\n","              epochs = 100,\n","              steps_per_epoch = (2000//16),\n","              validation_data = val_generator,\n","              validation_steps = (1000//16),\n","              callbacks = [CALLBACK]\n","             )\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C3()\n","    model.save(\"model_C3.h5\")\n"]},{"cell_type":"code","execution_count":4,"id":"faa282f0","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:26:34.803512Z","iopub.status.busy":"2022-06-26T14:26:34.802705Z","iopub.status.idle":"2022-06-26T14:26:45.154257Z","shell.execute_reply":"2022-06-26T14:26:45.153262Z"},"papermill":{"duration":10.476968,"end_time":"2022-06-26T14:26:45.156622","exception":false,"start_time":"2022-06-26T14:26:34.679654","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n","{'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}\n","Epoch 1/100\n","625/625 [==============================] - 3s 4ms/step - loss: 0.6646 - accuracy: 0.5818 - val_loss: 0.5882 - val_accuracy: 0.7557\n","Epoch 2/100\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4749 - accuracy: 0.7798 - val_loss: 0.4287 - val_accuracy: 0.8028\n"]}],"source":["# =====================================================================================================\n","# PROBLEM C4\n","#\n","# Build and train a classifier for the sarcasm dataset.\n","# The classifier should have a final layer with 1 neuron activated by sigmoid.\n","#\n","# Do not use lambda layers in your model.\n","#\n","# Dataset used in this problem is built by Rishabh Misra (https://rishabhmisra.github.io/publications).\n","#\n","# Desired accuracy and validation_accuracy > 75%\n","# =======================================================================================================\n","\n","import json\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.75 and logs.get('val_accuracy') > 0.75):\n","            self.model.stop_training = True\n","\n","def solution_C4():\n","    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sarcasm.json'\n","    urllib.request.urlretrieve(data_url, 'sarcasm.json')\n","\n","    # DO NOT CHANGE THIS CODE\n","    # Make sure you used all of these parameters or test may fail\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type = 'post'\n","    padding_type = 'post'\n","    oov_tok = \"<OOV>\"\n","    training_size = 20000\n","\n","    sentences = []\n","    labels = []\n","    # YOUR CODE HERE\n","    with open('sarcasm.json', 'r') as f:\n","        datastore = json.load(f)\n","        \n","    print(datastore[0])\n","    print(datastore[2])\n","\n","    for item in datastore:\n","        sentences.append(item['headline'])\n","        labels.append(item['is_sarcastic'])\n","    \n","    sentences_train = sentences[:training_size]\n","    labels_train = labels[:training_size]\n","    sentences_test = sentences[training_size:]\n","    labels_test = labels[training_size:]\n","    \n","    # Fit your tokenizer with training data\n","    tokenizer = Tokenizer(num_words = vocab_size,\n","                          oov_token = oov_tok\n","                         )\n","    \n","    tokenizer.fit_on_texts(sentences)\n","    \n","    train_sequences = tokenizer.texts_to_sequences(sentences_train)\n","    sentences_train = pad_sequences(train_sequences,\n","                                    maxlen = max_length,\n","                                    truncating = trunc_type,\n","                                    padding = padding_type\n","                                   )\n","    \n","    test_sequences = tokenizer.texts_to_sequences(sentences_test)\n","    sentences_test = pad_sequences(test_sequences,\n","                                   maxlen = max_length,\n","                                   truncating = trunc_type,\n","                                   padding = padding_type\n","                                  )\n","    \n","    labels_train = np.array(labels_train)\n","    labels_test = np.array(labels_test)\n","\n","    model = tf.keras.Sequential([\n","        # YOUR CODE HERE. DO not change the last layer or test may fail\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n","        tf.keras.layers.GlobalAveragePooling1D(),\n","        tf.keras.layers.Dense(32, activation = 'relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    \n","    model.compile(loss = 'binary_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(sentences_train,\n","              labels_train,\n","              epochs = 100,\n","              validation_data = (sentences_test, labels_test),\n","              callbacks = [CALLBACK]\n","             )\n","    \n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C4()\n","    model.save(\"model_C4.h5\")\n"]},{"cell_type":"code","execution_count":5,"id":"b4faff9a","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:26:45.412095Z","iopub.status.busy":"2022-06-26T14:26:45.41172Z","iopub.status.idle":"2022-06-26T14:26:49.469524Z","shell.execute_reply":"2022-06-26T14:26:49.468602Z"},"papermill":{"duration":4.188796,"end_time":"2022-06-26T14:26:49.4717","exception":false,"start_time":"2022-06-26T14:26:45.282904","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<PrefetchDataset shapes: ((None, None, 1), (None, None, 1)), types: (tf.float64, tf.float64)>\n","(2500,)\n","Epoch 1/100\n","10/10 [==============================] - 1s 26ms/step - loss: 0.2458 - mae: 0.4434\n","Epoch 2/100\n","10/10 [==============================] - 0s 23ms/step - loss: 0.0828 - mae: 0.2391\n","Epoch 3/100\n","10/10 [==============================] - 0s 24ms/step - loss: 0.0426 - mae: 0.1634\n","Epoch 4/100\n","10/10 [==============================] - 0s 23ms/step - loss: 0.0290 - mae: 0.1336\n","Epoch 5/100\n","10/10 [==============================] - 0s 23ms/step - loss: 0.0239 - mae: 0.1217\n"]}],"source":["# ============================================================================================\n","# PROBLEM C5\n","#\n","# Build and train a neural network model using the Daily Min Temperature.csv dataset.\n","# Use MAE as the metrics of your neural network model.\n","# We provided code for normalizing the data. Please do not change the code.\n","# Do not use lambda layers in your model.\n","#\n","# The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n","#\n","# Desired MAE < 0.19 on the normalized dataset.\n","# ============================================================================================\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","import urllib\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('mae') < 0.19 and epoch > 3):\n","            self.model.stop_training = True\n","\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_C5():\n","    data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n","    urllib.request.urlretrieve(data_url, 'daily-min-temperatures.csv')\n","\n","    time_step = []\n","    temps = []\n","\n","    with open('daily-min-temperatures.csv') as csvfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","        next(reader)\n","        step = 0\n","        for row in reader:\n","            temps.append(row[1])\n","            time_step.append(step)\n","            step = step + 1\n","\n","    series = np.array(temps).astype(np.float64)\n","\n","    # Normalization Function. DO NOT CHANGE THIS CODE\n","    min=np.min(series)\n","    max=np.max(series)\n","    series -= min\n","    series /= max\n","    time=np.array(time_step)\n","\n","    # DO NOT CHANGE THIS CODE\n","    split_time=2500\n","\n","    time_train = time[:split_time]\n","    x_train = series[:split_time]\n","    time_valid = time[split_time:]\n","    x_valid = series[split_time:] \n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size=64\n","    batch_size=256\n","    shuffle_buffer_size=1000\n","\n","    train_set=windowed_dataset(\n","        x_train, window_size, batch_size, shuffle_buffer_size)\n","    print(train_set)\n","    print(x_train.shape)\n","\n","    model=tf.keras.models.Sequential([\n","        # YOUR CODE HERE.\n","        tf.keras.layers.Conv1D(32, kernel_size = 1, input_shape = [None, 1]),\n","        tf.keras.layers.Dense(16, activation = 'relu'),\n","        tf.keras.layers.Dense(1),\n","    ])\n","    \n","    model.compile(loss = 'mse',\n","                  optimizer = 'sgd',\n","                  metrics = ['mae']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(train_set,\n","              epochs = 100,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    # YOUR CODE HERE\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model=solution_C5()\n","    model.save(\"model_C5.h5\")\n"]},{"cell_type":"code","execution_count":null,"id":"6c2fb432","metadata":{"papermill":{"duration":0.126556,"end_time":"2022-06-26T14:26:49.73865","exception":false,"start_time":"2022-06-26T14:26:49.612094","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":311.5469,"end_time":"2022-06-26T14:26:53.537346","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-06-26T14:21:41.990446","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}