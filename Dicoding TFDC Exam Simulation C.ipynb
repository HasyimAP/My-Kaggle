{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hasyimabdillah/dicoding-tfdc-exam-simulation-c?scriptVersionId=99365986\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","execution_count":1,"id":"8e727710","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:18:32.375057Z","iopub.status.busy":"2022-06-26T14:18:32.37417Z","iopub.status.idle":"2022-06-26T14:18:42.283763Z","shell.execute_reply":"2022-06-26T14:18:42.282682Z"},"papermill":{"duration":9.919334,"end_time":"2022-06-26T14:18:42.286361","exception":false,"start_time":"2022-06-26T14:18:32.367027","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-26 14:18:37.369139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:37.482354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:37.483107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:37.484917: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-06-26 14:18:37.488830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:37.489620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:37.490424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:39.712207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:39.713034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:39.713699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-06-26 14:18:39.714305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","2022-06-26 14:18:40.134614: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","1/1 [==============================] - 2s 2s/step - loss: 10.7482\n","Epoch 2/100\n","1/1 [==============================] - 0s 3ms/step - loss: 8.6832\n","Epoch 3/100\n","1/1 [==============================] - 0s 4ms/step - loss: 4.2436\n","Epoch 4/100\n","1/1 [==============================] - 0s 3ms/step - loss: 2.9350\n","Epoch 5/100\n","1/1 [==============================] - 0s 3ms/step - loss: 1.5805\n","Epoch 6/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.4869\n","Epoch 7/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.1158\n","Epoch 8/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0834\n","Epoch 9/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0717\n","Epoch 10/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0617\n","Epoch 11/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0532\n","Epoch 12/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0460\n","Epoch 13/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0397\n","Epoch 14/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0344\n","Epoch 15/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0298\n","Epoch 16/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0259\n","Epoch 17/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0225\n","Epoch 18/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0195\n","Epoch 19/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0170\n","Epoch 20/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0148\n","Epoch 21/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0129\n","Epoch 22/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0112\n","Epoch 23/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0098\n","Epoch 24/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0085\n","Epoch 25/100\n","1/1 [==============================] - 0s 8ms/step - loss: 0.0074\n","Epoch 26/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0065\n","Epoch 27/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0057\n","Epoch 28/100\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0050\n","Epoch 29/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0043\n","Epoch 30/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0038\n","Epoch 31/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0033\n","Epoch 32/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0029\n","Epoch 33/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0025\n","Epoch 34/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n","Epoch 35/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0019\n","Epoch 36/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0017\n","Epoch 37/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n","Epoch 38/100\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n","Epoch 39/100\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n","Epoch 40/100\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n","Epoch 41/100\n","1/1 [==============================] - 0s 5ms/step - loss: 8.7866e-04\n","Epoch 42/100\n","1/1 [==============================] - 0s 5ms/step - loss: 7.7016e-04\n","Epoch 43/100\n","1/1 [==============================] - 0s 4ms/step - loss: 6.7515e-04\n","Epoch 44/100\n","1/1 [==============================] - 0s 4ms/step - loss: 5.9193e-04\n","Epoch 45/100\n","1/1 [==============================] - 0s 4ms/step - loss: 5.1903e-04\n","Epoch 46/100\n","1/1 [==============================] - 0s 4ms/step - loss: 4.5515e-04\n","Epoch 47/100\n","1/1 [==============================] - 0s 5ms/step - loss: 3.9917e-04\n","Epoch 48/100\n","1/1 [==============================] - 0s 4ms/step - loss: 3.5011e-04\n","Epoch 49/100\n","1/1 [==============================] - 0s 4ms/step - loss: 3.0711e-04\n","Epoch 50/100\n","1/1 [==============================] - 0s 4ms/step - loss: 2.6941e-04\n","Epoch 51/100\n","1/1 [==============================] - 0s 4ms/step - loss: 2.3635e-04\n","Epoch 52/100\n","1/1 [==============================] - 0s 4ms/step - loss: 2.0737e-04\n","Epoch 53/100\n","1/1 [==============================] - 0s 5ms/step - loss: 1.8195e-04\n","Epoch 54/100\n","1/1 [==============================] - 0s 4ms/step - loss: 1.5966e-04\n","Epoch 55/100\n","1/1 [==============================] - 0s 4ms/step - loss: 1.4011e-04\n","Epoch 56/100\n","1/1 [==============================] - 0s 6ms/step - loss: 1.2295e-04\n","Epoch 57/100\n","1/1 [==============================] - 0s 3ms/step - loss: 1.0791e-04\n","Epoch 58/100\n","1/1 [==============================] - 0s 4ms/step - loss: 9.4706e-05\n","[[-0.01988405]\n"," [ 6.022438  ]]\n"]}],"source":["# =============================================================================\n","# PROBLEM C1\n","#\n","# Given two arrays, train a neural network model to match the X to the Y.\n","# Predict the model with new values of X [-2.0, 10.0]\n","# We provide the model prediction, do not change the code.\n","#\n","# The test infrastructure expects a trained model that accepts\n","# an input shape of [1]\n","# Do not use lambda layers in your model.\n","#\n","# Please be aware that this is a linear model.\n","# We will test your model with values in a range as defined in the array to make sure your model is linear.\n","#\n","# Desired loss (MSE) < 1e-4\n","# =============================================================================\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('loss') < 1e-4):\n","            self.model.stop_training = True\n","\n","def solution_C1():\n","    # DO NOT CHANGE THIS CODE\n","    X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n","    Y = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)\n","\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Dense(1, input_shape = [1]),\n","        tf.keras.layers.Dense(1)\n","    ])\n","    \n","    model.compile(loss = 'mse',\n","                  optimizer = tf.keras.optimizers.SGD(learning_rate = 0.05)\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(X,\n","              Y,\n","              epochs = 100,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    print(model.predict([-2.0, 10.0]))\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C1()\n","    model.save(\"model_C1.h5\")\n"]},{"cell_type":"code","execution_count":2,"id":"8b34a8f7","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:18:42.31625Z","iopub.status.busy":"2022-06-26T14:18:42.31537Z","iopub.status.idle":"2022-06-26T14:18:47.543652Z","shell.execute_reply":"2022-06-26T14:18:47.542741Z"},"papermill":{"duration":5.244916,"end_time":"2022-06-26T14:18:47.545908","exception":false,"start_time":"2022-06-26T14:18:42.300992","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/100\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2012 - accuracy: 0.9409 - val_loss: 0.1138 - val_accuracy: 0.9639\n"]}],"source":["# =============================================================================\n","# PROBLEM C2\n","#\n","# Create a classifier for the MNIST Handwritten digit dataset.\n","# The test will expect it to classify 10 classes.\n","#\n","# Don't use lambda layers in your model.\n","#\n","# Desired accuracy AND validation_accuracy > 91%\n","# =============================================================================\n","\n","import tensorflow as tf\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.91 and logs.get('val_accuracy') > 0.91):\n","            self.model.stop_training = True\n","\n","def solution_C2():\n","    mnist = tf.keras.datasets.mnist\n","\n","    # NORMALIZE YOUR IMAGE HERE\n","    (images_train, labels_train), (images_test, labels_test) = mnist.load_data()\n","    \n","    images_train = images_train / 255.\n","    images_test = images_test / 255.\n","\n","    # DEFINE YOUR MODEL HERE\n","    # End with 10 Neuron Dense, activated by softmax\n","    model = tf.keras.models.Sequential([\n","        tf.keras.layers.Flatten(input_shape = (28, 28)),\n","        tf.keras.layers.Dense(512, activation = 'relu'),\n","        tf.keras.layers.Dense(10, activation = 'softmax')\n","    ])\n","\n","    # COMPILE MODEL HERE\n","    model.compile(loss = 'sparse_categorical_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","\n","    # TRAIN YOUR MODEL HERE\n","    CALLBACK = myCallback()\n","    \n","    model.fit(images_train,\n","              labels_train,\n","              epochs = 100,\n","              validation_data = (images_test, labels_test),\n","              callbacks = [CALLBACK]\n","             )\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C2()\n","    model.save(\"model_C2.h5\")\n"]},{"cell_type":"code","execution_count":3,"id":"19f2b2c1","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:18:47.578604Z","iopub.status.busy":"2022-06-26T14:18:47.578293Z","iopub.status.idle":"2022-06-26T14:20:28.534425Z","shell.execute_reply":"2022-06-26T14:20:28.533412Z"},"papermill":{"duration":100.975575,"end_time":"2022-06-26T14:20:28.536896","exception":false,"start_time":"2022-06-26T14:18:47.561321","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n","Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2022-06-26 14:18:52.003037: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["125/125 [==============================] - 24s 138ms/step - loss: 0.7114 - accuracy: 0.5335 - val_loss: 0.7018 - val_accuracy: 0.5040\n","Epoch 2/5\n","125/125 [==============================] - 19s 153ms/step - loss: 0.6823 - accuracy: 0.5875 - val_loss: 0.7238 - val_accuracy: 0.5000\n","Epoch 3/5\n","125/125 [==============================] - 17s 140ms/step - loss: 0.6612 - accuracy: 0.6125 - val_loss: 0.6861 - val_accuracy: 0.5726\n","Epoch 4/5\n","125/125 [==============================] - 17s 138ms/step - loss: 0.6570 - accuracy: 0.6260 - val_loss: 0.7536 - val_accuracy: 0.5141\n","Epoch 5/5\n","125/125 [==============================] - 18s 141ms/step - loss: 0.6334 - accuracy: 0.6615 - val_loss: 0.6379 - val_accuracy: 0.6331\n"]}],"source":["# =======================================================================================================\n","# PROBLEM C3\n","#\n","# Build a CNN based classifier for Cats vs Dogs dataset.\n","# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n","# This is unlabeled data, use ImageDataGenerator to automatically label it.\n","# Don't use lambda layers in your model.\n","#\n","# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n","#\n","# Desired accuracy and validation_accuracy > 72%\n","# ========================================================================================================\n","\n","import tensorflow as tf\n","import urllib.request\n","import zipfile\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.72 and logs.get('val_accuracy') > 0.72):\n","            self.model.stop_training = True\n","\n","def solution_C3():\n","    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n","    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n","    local_file = 'cats_and_dogs.zip'\n","    zip_ref = zipfile.ZipFile(local_file, 'r')\n","    zip_ref.extractall('data/')\n","    zip_ref.close()\n","\n","    BASE_DIR = 'data/cats_and_dogs_filtered'\n","    train_dir = os.path.join(BASE_DIR, 'train')\n","    validation_dir = os.path.join(BASE_DIR, 'validation')\n","\n","    train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                       rotation_range = 0.1,\n","                                       width_shift_range = 0.1,\n","                                       height_shift_range = 0.1,\n","                                       shear_range = 0.1,\n","                                       zoom_range = 0.2,\n","                                       horizontal_flip = True\n","                                      )\n","    \n","    val_datagen = ImageDataGenerator(rescale = 1./255.)\n","\n","    # YOUR IMAGE SIZE SHOULD BE 150x150\n","    # Make sure you used \"binary\"\n","    train_generator = train_datagen.flow_from_directory(directory = train_dir,\n","                                                        target_size = (150, 150),\n","                                                        color_mode = 'rgb',\n","                                                        class_mode = 'binary',\n","                                                        shuffle = True,\n","                                                        batch_size = 16\n","                                                       )\n","    \n","    val_generator = val_datagen.flow_from_directory(directory = validation_dir,\n","                                                    target_size = (150, 150),\n","                                                    color_mode = 'rgb',\n","                                                    class_mode = 'binary',\n","                                                    shuffle = True,\n","                                                    batch_size = 16\n","                                                   )\n","    \n","    model = tf.keras.models.Sequential([\n","        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n","        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), input_shape = (150, 150, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Conv2D(16, kernel_size = (3, 3), activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPooling2D((2, 2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation = 'relu'),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dense(64, activation = 'relu'),\n","        tf.keras.layers.Dense(32, activation = 'relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(1, activation = 'sigmoid')\n","    ])\n","    \n","    model.compile(loss = 'binary_crossentropy',\n","                  optimizer = RMSprop(learning_rate = 1e-3),\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(train_generator,\n","              epochs = 5,\n","              steps_per_epoch = (2000//16),\n","              validation_data = val_generator,\n","              validation_steps = (1000//16),\n","              callbacks = [CALLBACK]\n","             )\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C3()\n","    model.save(\"model_C3.h5\")\n"]},{"cell_type":"code","execution_count":4,"id":"334d191d","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:20:28.645097Z","iopub.status.busy":"2022-06-26T14:20:28.643295Z","iopub.status.idle":"2022-06-26T14:20:34.526529Z","shell.execute_reply":"2022-06-26T14:20:34.525538Z"},"papermill":{"duration":5.939672,"end_time":"2022-06-26T14:20:34.528992","exception":false,"start_time":"2022-06-26T14:20:28.58932","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n","{'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}\n","Epoch 1/100\n","625/625 [==============================] - 2s 3ms/step - loss: 0.6678 - accuracy: 0.5867 - val_loss: 0.5998 - val_accuracy: 0.7429\n","Epoch 2/100\n","625/625 [==============================] - 2s 3ms/step - loss: 0.4860 - accuracy: 0.7809 - val_loss: 0.4333 - val_accuracy: 0.7982\n"]}],"source":["# =====================================================================================================\n","# PROBLEM C4\n","#\n","# Build and train a classifier for the sarcasm dataset.\n","# The classifier should have a final layer with 1 neuron activated by sigmoid.\n","#\n","# Do not use lambda layers in your model.\n","#\n","# Dataset used in this problem is built by Rishabh Misra (https://rishabhmisra.github.io/publications).\n","#\n","# Desired accuracy and validation_accuracy > 75%\n","# =======================================================================================================\n","\n","import json\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('accuracy') > 0.75 and logs.get('val_accuracy') > 0.75):\n","            self.model.stop_training = True\n","\n","def solution_C4():\n","    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sarcasm.json'\n","    urllib.request.urlretrieve(data_url, 'sarcasm.json')\n","\n","    # DO NOT CHANGE THIS CODE\n","    # Make sure you used all of these parameters or test may fail\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type = 'post'\n","    padding_type = 'post'\n","    oov_tok = \"<OOV>\"\n","    training_size = 20000\n","\n","    sentences = []\n","    labels = []\n","    # YOUR CODE HERE\n","    with open('sarcasm.json', 'r') as f:\n","        datastore = json.load(f)\n","        \n","    print(datastore[0])\n","    print(datastore[2])\n","\n","    for item in datastore:\n","        sentences.append(item['headline'])\n","        labels.append(item['is_sarcastic'])\n","    \n","    sentences_train = sentences[:training_size]\n","    labels_train = labels[:training_size]\n","    sentences_test = sentences[training_size:]\n","    labels_test = labels[training_size:]\n","    \n","    # Fit your tokenizer with training data\n","    tokenizer = Tokenizer(num_words = vocab_size,\n","                          oov_token = oov_tok\n","                         )\n","    \n","    tokenizer.fit_on_texts(sentences)\n","    \n","    train_sequences = tokenizer.texts_to_sequences(sentences_train)\n","    sentences_train = pad_sequences(train_sequences,\n","                                    maxlen = max_length,\n","                                    truncating = trunc_type,\n","                                    padding = padding_type\n","                                   )\n","    \n","    test_sequences = tokenizer.texts_to_sequences(sentences_test)\n","    sentences_test = pad_sequences(test_sequences,\n","                                   maxlen = max_length,\n","                                   truncating = trunc_type,\n","                                   padding = padding_type\n","                                  )\n","    \n","    labels_train = np.array(labels_train)\n","    labels_test = np.array(labels_test)\n","\n","    model = tf.keras.Sequential([\n","        # YOUR CODE HERE. DO not change the last layer or test may fail\n","        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n","        tf.keras.layers.GlobalAveragePooling1D(),\n","        tf.keras.layers.Dense(32, activation = 'relu'),\n","        tf.keras.layers.Dense(1, activation='sigmoid')\n","    ])\n","    \n","    model.compile(loss = 'binary_crossentropy',\n","                  optimizer = 'adam',\n","                  metrics = ['accuracy']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(sentences_train,\n","              labels_train,\n","              epochs = 100,\n","              validation_data = (sentences_test, labels_test),\n","              callbacks = [CALLBACK]\n","             )\n","    \n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C4()\n","    model.save(\"model_C4.h5\")\n"]},{"cell_type":"code","execution_count":5,"id":"aff6e8ed","metadata":{"execution":{"iopub.execute_input":"2022-06-26T14:20:34.643241Z","iopub.status.busy":"2022-06-26T14:20:34.642419Z","iopub.status.idle":"2022-06-26T14:20:39.263204Z","shell.execute_reply":"2022-06-26T14:20:39.262277Z"},"papermill":{"duration":4.680118,"end_time":"2022-06-26T14:20:39.265387","exception":false,"start_time":"2022-06-26T14:20:34.585269","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<PrefetchDataset shapes: ((None, None, 1), (None, None, 1)), types: (tf.float64, tf.float64)>\n","(2500,)\n","Epoch 1/100\n","10/10 [==============================] - 1s 26ms/step - loss: 0.1617 - mae: 0.3600\n","Epoch 2/100\n","10/10 [==============================] - 0s 24ms/step - loss: 0.0661 - mae: 0.2174\n","Epoch 3/100\n","10/10 [==============================] - 0s 24ms/step - loss: 0.0379 - mae: 0.1570\n","Epoch 4/100\n","10/10 [==============================] - 0s 23ms/step - loss: 0.0260 - mae: 0.1273\n","Epoch 5/100\n","10/10 [==============================] - 0s 22ms/step - loss: 0.0208 - mae: 0.1133\n"]}],"source":["# ============================================================================================\n","# PROBLEM C5\n","#\n","# Build and train a neural network model using the Daily Min Temperature.csv dataset.\n","# Use MAE as the metrics of your neural network model.\n","# We provided code for normalizing the data. Please do not change the code.\n","# Do not use lambda layers in your model.\n","#\n","# The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n","#\n","# Desired MAE < 0.19 on the normalized dataset.\n","# ============================================================================================\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","import urllib\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if (logs.get('mae') < 0.19 and epoch > 3):\n","            self.model.stop_training = True\n","\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_C5():\n","    data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n","    urllib.request.urlretrieve(data_url, 'daily-min-temperatures.csv')\n","\n","    time_step = []\n","    temps = []\n","\n","    with open('daily-min-temperatures.csv') as csvfile:\n","        reader = csv.reader(csvfile, delimiter=',')\n","        next(reader)\n","        step = 0\n","        for row in reader:\n","            temps.append(row[1])\n","            time_step.append(step)\n","            step = step + 1\n","\n","    series = np.array(temps).astype(np.float64)\n","\n","    # Normalization Function. DO NOT CHANGE THIS CODE\n","    min=np.min(series)\n","    max=np.max(series)\n","    series -= min\n","    series /= max\n","    time=np.array(time_step)\n","\n","    # DO NOT CHANGE THIS CODE\n","    split_time=2500\n","\n","    time_train = time[:split_time]\n","    x_train = series[:split_time]\n","    time_valid = time[split_time:]\n","    x_valid = series[split_time:] \n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size=64\n","    batch_size=256\n","    shuffle_buffer_size=1000\n","\n","    train_set=windowed_dataset(\n","        x_train, window_size, batch_size, shuffle_buffer_size)\n","    print(train_set)\n","    print(x_train.shape)\n","\n","    model=tf.keras.models.Sequential([\n","        # YOUR CODE HERE.\n","        tf.keras.layers.Conv1D(32, kernel_size = 1, input_shape = [None, 1]),\n","        tf.keras.layers.Dense(16, activation = 'relu'),\n","        tf.keras.layers.Dense(1),\n","    ])\n","    \n","    model.compile(loss = 'mse',\n","                  optimizer = 'sgd',\n","                  metrics = ['mae']\n","                 )\n","    \n","    CALLBACK = myCallback()\n","    \n","    model.fit(train_set,\n","              epochs = 100,\n","              callbacks = [CALLBACK]\n","             )\n","\n","    # YOUR CODE HERE\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model=solution_C5()\n","    model.save(\"model_C5.h5\")\n"]},{"cell_type":"code","execution_count":null,"id":"18106e08","metadata":{"papermill":{"duration":0.057084,"end_time":"2022-06-26T14:20:39.381016","exception":false,"start_time":"2022-06-26T14:20:39.323932","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":138.461383,"end_time":"2022-06-26T14:20:42.785057","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-06-26T14:18:24.323674","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}